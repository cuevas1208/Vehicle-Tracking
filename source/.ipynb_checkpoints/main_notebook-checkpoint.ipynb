{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Techniques used in this project were learned from Udacity Self-Driving Car program and were adapted to do this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.feature import hog\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lesson_Functions import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import pickle\n",
    "\n",
    "if not os.path.isfile(\"images_pickle.p\"):\n",
    "    collect_data() \n",
    "    dist_pickle = pickle.load( open(\"images_pickle.p\", \"rb\" ) )\n",
    "    cars = dist_pickle[\"cars\"]\n",
    "    notcars = dist_pickle[\"notcars\"]\n",
    "else:\n",
    "    # Load the camera calibration result \n",
    "    dist_pickle = pickle.load( open(\"images_pickle.p\", \"rb\" ) )\n",
    "    cars = dist_pickle[\"cars\"]\n",
    "    notcars = dist_pickle[\"notcars\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a clasifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "def build_clasifier():\n",
    "    car_features = extract_features(cars, color_space=color_space, \n",
    "                            spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                            orient=orient, pix_per_cell=pix_per_cell, \n",
    "                            cell_per_block=cell_per_block, \n",
    "                            hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                            hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "    notcar_features = extract_features(notcars, color_space=color_space, \n",
    "                            spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                            orient=orient, pix_per_cell=pix_per_cell, \n",
    "                            cell_per_block=cell_per_block, \n",
    "                            hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                            hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "    \n",
    "    # Create an array stack of feature vectors\n",
    "    X = np.vstack((car_features, notcar_features)).astype(np.float64)                        \n",
    "    # Fit a per-column scaler\n",
    "    X_scaler = StandardScaler().fit(X)\n",
    "    # Apply the scaler to X\n",
    "    scaled_X = X_scaler.transform(X)\n",
    "\n",
    "    # Define the labels vector\n",
    "    y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "\n",
    "\n",
    "    # Split up data into randomized training and test sets\n",
    "    rand_state = np.random.randint(0, 100)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        scaled_X, y, test_size=0.2, random_state=rand_state)\n",
    "\n",
    "    #Display results\n",
    "    print('Feature vector length:', len(X_train[0]))\n",
    "    # Use a linear SVC \n",
    "    # svc = LinearSVC()\n",
    "    #svc = svm.SVC(decision_function_shape='ovo')\n",
    "    #svc = svm.SVC(C=10, kernel='linear', degree=3, gamma='auto', coef0=10, shrinking=True, probability=False, tol=0.001, \n",
    "    #             cache_size=200, class_weight=None, verbose=True, max_iter=-1, decision_function_shape='ovo', random_state=3)\n",
    "    svc = svm.SVC(C=1.0, kernel='rbf', degree=3, gamma='auto', coef0=0.0, shrinking=True, probability=False, tol=0.001, \n",
    "                cache_size=200, decision_function_shape='ovo', random_state=None)\n",
    "    #Check the training time for the SVC\n",
    "    svc.fit(X_train, y_train)\n",
    "    \n",
    "    # Check the score of the SVC\n",
    "    print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\n",
    "    # Check the prediction time for a single sample\n",
    "    n_predict = 10\n",
    "    print('My SVC predicts:     ', svc.predict(X_test[0:n_predict]))\n",
    "    print('For these',n_predict, 'labels: ', y_test[0:n_predict])\n",
    "\n",
    "    # Save the camera calibration result \n",
    "    dist_pickle = {}\n",
    "    dist_pickle[\"svc\"] = svc\n",
    "    dist_pickle[\"scaler\"] = X_scaler\n",
    "    dist_pickle[\"orient\"] = orient\n",
    "    dist_pickle[\"pix_per_cell\"] = pix_per_cell\n",
    "    dist_pickle[\"cell_per_block\"] = cell_per_block\n",
    "    dist_pickle[\"spatial_size\"] = spatial_size\n",
    "    dist_pickle[\"hist_bins\"] = hist_bins\n",
    "    dist_pickle[\"cars\"] = cars\n",
    "    dist_pickle[\"notcars\"] = notcars\n",
    "    pickle.dump( dist_pickle, open( \"svc_pickle.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage.measurements import label\n",
    "\n",
    "def apply_threshold(heatmap, threshold):\n",
    "    # Zero out pixels below the threshold\n",
    "    heatmap[heatmap <= threshold] = 0\n",
    "    # Return thresholded map\n",
    "    return heatmap\n",
    "\n",
    "def add_heat(heatmap, box_list):\n",
    "    # Iterate through list of bboxes\n",
    "    for box in box_list:\n",
    "        # Add += 1 for all pixels inside each bbox\n",
    "        # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "        heatmap[box[0]:box[1], box[2]:box[3]] += 1\n",
    "\n",
    "    # Return updated heatmap\n",
    "    return heatmap# Iterate through list of bboxes\n",
    "\n",
    "def draw_labeled_bboxes(img, labels):\n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        # Draw the box on the image\n",
    "        cv2.rectangle(img, bbox[0], bbox[1], (0,0,255), 6)\n",
    "    # Return the image\n",
    "    return img\n",
    "        \n",
    "# Define a single function that can extract features using hog sub-sampling and make predictions\n",
    "# The code below defines a single function find_cars that's able to both extract features and make predictions.\n",
    "def find_cars(img, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, \n",
    "              cell_per_block, spatial_size, hist_bins, spatial_feat = True, hist_feat = True):\n",
    "    box = [] \n",
    "    box.append(None)\n",
    "    box.append(None)\n",
    "    box_list = []\n",
    "    draw_img = np.copy(img)\n",
    "    heatmap = np.zeros_like(img[:,:,0])\n",
    "    #img = img.astype(np.float32)/255\n",
    "        \n",
    "    img_tosearch = img[ystart:ystop,:,:]\n",
    "    ctrans_tosearch = convert_color(img_tosearch, color_space=color_space)\n",
    "    if scale != 1:\n",
    "        imshape = ctrans_tosearch.shape\n",
    "        ctrans_tosearch = cv2.resize(ctrans_tosearch, (np.int(imshape[1]/scale), \n",
    "                                                       np.int(imshape[0]/scale)))\n",
    "        \n",
    "    ch1 = ctrans_tosearch[:,:,0]\n",
    "    ch2 = ctrans_tosearch[:,:,1]\n",
    "    ch3 = ctrans_tosearch[:,:,2]\n",
    "\n",
    "    # Define blocks and steps as above\n",
    "    nxblocks = (ch1.shape[1] // pix_per_cell)-1\n",
    "    nyblocks = (ch1.shape[0] // pix_per_cell)-1 \n",
    "    \n",
    "    nfeat_per_block = orient*cell_per_block**2\n",
    "    \n",
    "    # 64 is the sampling rate, with 8 cells and 8 pix per cell\n",
    "    window = 64\n",
    "    nblocks_per_window = (window // pix_per_cell)-1 \n",
    "    cells_per_step = 2  # Instead of overlap, define how many cells to step\n",
    "    nxsteps = (nxblocks - nblocks_per_window) // cells_per_step\n",
    "    nysteps = (nyblocks - nblocks_per_window) // cells_per_step\n",
    "    \n",
    "    # Compute individual channel HOG features for the entire image\n",
    "    hog1 = get_hog_features(ch1, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog2 = get_hog_features(ch2, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog3 = get_hog_features(ch3, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    \n",
    "    for xb in range(nxsteps):\n",
    "        for yb in range(nysteps):\n",
    "            ypos = yb*cells_per_step\n",
    "            xpos = xb*cells_per_step\n",
    "            \n",
    "            file_features = []\n",
    "           \n",
    "            # Extract HOG for this patch\n",
    "            hog_feat1 = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_feat2 = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_feat3 = hog3[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_features = np.hstack((hog_feat1, hog_feat2, hog_feat3))\n",
    "\n",
    "            xleft = xpos*pix_per_cell\n",
    "            ytop = ypos*pix_per_cell\n",
    "\n",
    "            # Extract the image patch\n",
    "            feature_image = cv2.resize(ctrans_tosearch[ytop:ytop+window, xleft:xleft+window], (64,64))\n",
    "          \n",
    "            # Get color features\n",
    "            if (spatial_feat):\n",
    "                spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "                file_features.append(spatial_features)\n",
    "            if (hist_feat):\n",
    "                #hist_features = color_hist(subimg, nbins=hist_bins)\n",
    "                hist_features = color_hist(feature_image, nbins=hist_bins)\n",
    "                file_features.append(hist_features)\n",
    "                \n",
    "            file_features.append(hog_features) \n",
    "            \n",
    "            features = np.concatenate(file_features)\n",
    "\n",
    "            # Scale features and make a prediction\n",
    "            #test_features = X_scaler.transform(file_features)\n",
    "            #test_prediction = svc.predict(test_features)\n",
    "            \n",
    "            #scaled_X contains the normalized feature vectors\n",
    "            test_features = X_scaler.transform(np.array(features).reshape(1, -1))\n",
    "            test_prediction = svc.predict(test_features)\n",
    "            \n",
    "            if test_prediction == 1:\n",
    "                xbox_left = np.int(xleft*scale)\n",
    "                ytop_draw = np.int(ytop*scale)\n",
    "                win_draw = np.int(window*scale)\n",
    "                box = ((ytop_draw+ystart,ytop_draw+win_draw+ystart,xbox_left,xbox_left+win_draw))\n",
    "                box_list.append(box)\n",
    "    return box_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile(\"svc_pickle.p\"):\n",
    "    build_clasifier()\n",
    "else:\n",
    "    # Load the camera calibration result \n",
    "    dist_pickle = pickle.load(open(\"svc_pickle.p\", \"rb\" ))\n",
    "    svc = dist_pickle[\"svc\"]\n",
    "    X_scaler = dist_pickle[\"scaler\"]\n",
    "    orient = dist_pickle[\"orient\"]\n",
    "    pix_per_cell = dist_pickle[\"pix_per_cell\"]\n",
    "    cell_per_block = dist_pickle[\"cell_per_block\"]\n",
    "    spatial_size = dist_pickle[\"spatial_size\"]\n",
    "    hist_bins = dist_pickle[\"hist_bins\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vector length: 3576\n",
      "Test Accuracy of SVC =  0.985\n",
      "My SVC predicts:      [ 1.  0.  1.  1.  0.  0.  1.  1.  0.  1.]\n",
      "For these 10 labels:  [ 1.  0.  1.  1.  0.  0.  1.  1.  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "### Parameters\n",
    "color_space = 'YCrCb'     # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "\n",
    "##HOG Parameters\n",
    "orient = 6               # 9->16                                ++ =           --squares\n",
    "pix_per_cell = 8         # 8->16                                ++ = --SIZE\n",
    "cell_per_block = 2       # 5->helps with normalizaiton          ++ = --SIZE\n",
    "hog_channel = \"ALL\"      # 0 Can be 0, 1, 2, or \"ALL\"           ++ =           ++squares\n",
    "\n",
    "#bin_spatial Parameters  ++increaes SIZE\n",
    "spatial_size = (16, 16)  # (40, 40)Spatial binning dimensions    ++ = +squares   \n",
    "hist_bins = 16           # 32      Number of histogram bins      ++ = +squares\n",
    "\n",
    "#Enable features  \n",
    "spatial_feat = False     # Spatial features on or off\n",
    "hist_feat = True         # Histogram features on or off\n",
    "hog_feat = True          # HOG features on or off\n",
    "    \n",
    "xy_overlap=(0.5, 0.5)\n",
    "build_clasifier()\n",
    "\n",
    "dist_pickle = pickle.load( open(\"svc_pickle.p\", \"rb\" ) )\n",
    "svc = dist_pickle[\"svc\"]\n",
    "X_scaler = dist_pickle[\"scaler\"]\n",
    "orient = dist_pickle[\"orient\"]\n",
    "pix_per_cell = dist_pickle[\"pix_per_cell\"]\n",
    "cell_per_block = dist_pickle[\"cell_per_block\"]\n",
    "spatial_size = dist_pickle[\"spatial_size\"]\n",
    "hist_bins = dist_pickle[\"hist_bins\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage.measurements import label\n",
    "scales = [1.5, 1.2, 1.6, 2.1, 1.8]\n",
    "count = 0 \n",
    "toggle = 0\n",
    "delay = 4\n",
    "\n",
    "#initialice list\n",
    "boxes_list = []\n",
    "for scale in scales: \n",
    "    boxes_list.append(None)\n",
    "\n",
    "\n",
    "def pipeline(image):\n",
    "    global count, boxes_list, toggle\n",
    "\n",
    "    #getIndex   \n",
    "    if count > len(scales)-1:\n",
    "        count = 0\n",
    "    \n",
    "    if (toggle == 0):\n",
    "        #identefy size of the screen to work on\n",
    "        y_start_stop=[int(image.shape[0]/2), image.shape[0]-50]\n",
    "        boxes = find_cars(image, y_start_stop[0], y_start_stop[1], scales[count], svc, X_scaler, \n",
    "                                 orient, pix_per_cell, cell_per_block, spatial_size, hist_bins,\n",
    "                                 spatial_feat=spatial_feat, hist_feat = hist_feat)\n",
    "    \n",
    "        boxes_list[count]= boxes\n",
    "        count = count + 1\n",
    "        toggle = delay\n",
    "    else:\n",
    "        img_label = image\n",
    "        \n",
    "    #stack heatmaps\n",
    "    try:\n",
    "        #Initilice heatmap\n",
    "        heatmap = np.zeros_like(image[:,:,0])\n",
    "        \n",
    "        # Add heat to each box in box list\n",
    "        heatmap = add_heat(heatmap, boxes_list[0])\n",
    "        heatmap = add_heat(heatmap, boxes_list[1])\n",
    "        heatmap = add_heat(heatmap, boxes_list[2])\n",
    "        heatmap = add_heat(heatmap, boxes_list[3])\n",
    "        heatmap = add_heat(heatmap, boxes_list[4])\n",
    "        \n",
    "        heatmap = apply_threshold(heatmap, 2)\n",
    "        \n",
    "        # Find final boxes from heatmap using label function\n",
    "        labels = label(heatmap)\n",
    "        draw_boxes = draw_labeled_bboxes(np.copy(image), labels)\n",
    "    except:\n",
    "        draw_boxes = image\n",
    "\n",
    "    toggle -= 1\n",
    "    #printImg(img_label, draw_boxes, img1_title = 'Input Image', img2_title = 'Output Image')\n",
    "    return draw_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = glob.glob('../test_images/test*.jpg')\n",
    "for idx, image_location in enumerate(images):\n",
    "    image = mpimg.imread('../test_images/'+image_location)\n",
    "    for i in range (len(scales)*delay-(delay-1)):\n",
    "        draw_boxes = pipeline(image)\n",
    "    print('output')\n",
    "    printImg(image, draw_boxes, img1_title = 'Input Image', img2_title = 'Output Image')\n",
    "    if (idx == 5):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Video"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from moviepy.editor import *\n",
    "#input_video = '../images/test_video.mp4'\n",
    "input_video = '../images/project_video.mp4'\n",
    "output_video = '../output/outputvideo__10.mp4'\n",
    "clip1 = VideoFileClip(input_video)\n",
    "video_clip = clip1.fl_image(pipeline)\n",
    "video_clip.write_videofile(output_video, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
